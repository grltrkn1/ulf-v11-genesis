name: Metric ATL Validation Run

on:
  workflow_dispatch: # Allows manual triggering from the GitHub Actions UI

jobs:
  run-full-asc-cycle:
    name: Run Autonomous Scientific Cycle
    runs-on: ubuntu-latest
    timeout-minutes: 90

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install Python dependencies
        run: |
          pip install -r requirements.txt

      - name: Run Experiment Engine (Simulation)
        id: simulation
        run: |
          echo "Running simulate_hf_planning.py..."
          python scripts/simulate_hf_planning.py --config config/experiment.yaml --output results.csv

      - name: Run Analysis Engine
        id: analysis
        run: |
          echo "Running analyze_results.py..."
          python analysis/analyze_results.py results.csv --output-file analysis_summary.txt

      - name: Run SEI Feedback Agent
        id: sei-agent
        if: success() # Only run if simulation and analysis succeed
        env:
          GITHUB_TOKEN: ${{ secrets.SEI_AUTOMATION_TOKEN }}
        run: |
          echo "Running SEI Feedback Agent..."
          python tools/sei_feedback_agent.py analysis_summary.txt --repo ${{ github.repository }} --token $GITHUB_TOKEN

      - name: Upload Experiment Artifacts
        if: always() # Upload artifacts even if a step fails, for debugging
        uses: actions/upload-artifact@v4
        with:
          name: metric_validation_report-${{ github.run_id }}
          path: |
            results.csv
            analysis_summary.txt
            analysis_plots/
